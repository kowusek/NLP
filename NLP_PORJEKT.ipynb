{"cells":[{"cell_type":"markdown","source":["Prepare enviroment"],"metadata":{"id":"qkVDIKuwHTI8"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":162285,"status":"ok","timestamp":1673719846452,"user":{"displayName":"Dan G","userId":"10633818666769653523"},"user_tz":-60},"id":"YFwfpKl1waoR","outputId":"db3b60a2-fa9c-4f63-9af1-a4883e1003d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mosesdecoder'...\n","remote: Enumerating objects: 148097, done.\u001b[K\n","remote: Counting objects: 100% (525/525), done.\u001b[K\n","remote: Compressing objects: 100% (229/229), done.\u001b[K\n","remote: Total 148097 (delta 323), reused 441 (delta 292), pack-reused 147572\u001b[K\n","Receiving objects: 100% (148097/148097), 129.88 MiB | 19.29 MiB/s, done.\n","Resolving deltas: 100% (114349/114349), done.\n","Cloning into 'subword-nmt'...\n","remote: Enumerating objects: 597, done.\u001b[K\n","remote: Counting objects: 100% (21/21), done.\u001b[K\n","remote: Compressing objects: 100% (17/17), done.\u001b[K\n","remote: Total 597 (delta 8), reused 12 (delta 4), pack-reused 576\u001b[K\n","Receiving objects: 100% (597/597), 252.23 KiB | 1.36 MiB/s, done.\n","Resolving deltas: 100% (357/357), done.\n","Cloning into 'fairseq'...\n","remote: Enumerating objects: 34294, done.\u001b[K\n","remote: Total 34294 (delta 0), reused 0 (delta 0), pack-reused 34294\u001b[K\n","Receiving objects: 100% (34294/34294), 23.75 MiB | 20.93 MiB/s, done.\n","Resolving deltas: 100% (24982/24982), done.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 KB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacremoses) (2022.6.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses) (1.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sacremoses) (4.64.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=2a1147b01a8468c75b2a6bc01fa2ad689fab4bcea04b967621d4be814dd693d2\n","  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n","Successfully built sacremoses\n","Installing collected packages: sacremoses\n","Successfully installed sacremoses-0.0.53\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.13.9-py2.py3-none-any.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (2.25.1)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.13.0-py2.py3-none-any.whl (177 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 KB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle\n","  Downloading setproctitle-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (3.19.6)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from wandb) (4.4.0)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.8/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from wandb) (6.0)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.15.0)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=af0c13b888e1037408352d560956126fc18085d7bb23a0b0cf4a5329ce82794a\n","  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n","Successfully built pathtools\n","Installing collected packages: pathtools, urllib3, smmap, setproctitle, docker-pycreds, sentry-sdk, gitdb, GitPython, wandb\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed GitPython-3.1.30 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.13.0 setproctitle-1.3.2 smmap-5.0.0 urllib3-1.26.14 wandb-0.13.9\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu113\n","Collecting torch==1.12.1+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torch-1.12.1%2Bcu113-cp38-cp38-linux_x86_64.whl (1837.7 MB)\n","\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m133.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 1837744128 bytes == 0x3292000 @  0x7fb1d334c1e7 0x4d30a0 0x4d312c 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4997a2\n","\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m135.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mtcmalloc: large alloc 2297184256 bytes == 0x70b2e000 @  0x7fb1d334d615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941\n","tcmalloc: large alloc 1837744128 bytes == 0x3292000 @  0x7fb1d334c1e7 0x4d30a0 0x5dede2 0x6758aa 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4fe318 0x5da092 0x62042c 0x5d8d8c 0x561f80 0x4fd2db 0x4997c7 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m880.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.13.1+cu113\n","  Downloading https://download.pytorch.org/whl/cu113/torchvision-0.13.1%2Bcu113-cp38-cp38-linux_x86_64.whl (23.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio==0.12.1\n","  Downloading https://download.pytorch.org/whl/cu113/torchaudio-0.12.1%2Bcu113-cp38-cp38-linux_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.12.1+cu113) (4.4.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1+cu113) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1+cu113) (1.21.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision==0.13.1+cu113) (2.25.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1+cu113) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1+cu113) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1+cu113) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision==0.13.1+cu113) (2.10)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.13.0+cu116\n","    Uninstalling torch-1.13.0+cu116:\n","      Successfully uninstalled torch-1.13.0+cu116\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.14.0+cu116\n","    Uninstalling torchvision-0.14.0+cu116:\n","      Successfully uninstalled torchvision-0.14.0+cu116\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.13.0+cu116\n","    Uninstalling torchaudio-0.13.0+cu116:\n","      Successfully uninstalled torchaudio-0.13.0+cu116\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.12.1+cu113 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.12.1+cu113 torchaudio-0.12.1+cu113 torchvision-0.13.1+cu113\n","/content/fairseq\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fairseq==0.12.2\n","  Downloading fairseq-0.12.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting hydra-core<1.1,>=1.0.7\n","  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 KB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting omegaconf<2.1\n","  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n","Collecting bitarray\n","  Downloading bitarray-2.6.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (240 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.4/240.4 KB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (1.15.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (1.12.1+cu113)\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (2022.6.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (4.64.1)\n","Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (0.12.1+cu113)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (1.21.6)\n","Collecting sacrebleu>=1.4.12\n","  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.2) (0.29.32)\n","Collecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2) (5.10.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (4.4.0)\n","Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (6.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (4.9.2)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.8.10)\n","Collecting portalocker\n","  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n","Collecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi->fairseq==0.12.2) (2.21)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==0.12.2) (3.11.0)\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141231 sha256=d7d300f55d50b0848df085f7867b741daa54d2ace932c61990bfbe47b105db71\n","  Stored in directory: /root/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n","Successfully installed antlr4-python3-runtime-4.8 bitarray-2.6.2 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.6.0 sacrebleu-2.3.1\n","/content\n"]}],"source":["! git clone https://github.com/moses-smt/mosesdecoder.git\n","! git clone https://github.com/rsennrich/subword-nmt.git\n","! git clone https://github.com/pytorch/fairseq\n","! pip install sacremoses\n","! pip install wandb\n","! pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu113\n","%cd fairseq\n","!pip install fairseq==0.12.2\n","%cd ..\n","! cp -r /content/subword-nmt /content/fairseq/examples/backtranslation\n","! cp -r /content/mosesdecoder /content/fairseq/examples/backtranslation"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","! mkdir /content/drive/MyDrive/NLP"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yI2a7QWEHVux","executionInfo":{"status":"ok","timestamp":1673423385666,"user_tz":-60,"elapsed":16548,"user":{"displayName":"Dan G","userId":"10633818666769653523"}},"outputId":"6a4705bf-c9e5-4590-c34c-66b5e1296ec1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import wandb\n","wandb.login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"5u-c64VyMBJ6","executionInfo":{"status":"ok","timestamp":1673423412302,"user_tz":-60,"elapsed":7022,"user":{"displayName":"Dan G","userId":"10633818666769653523"}},"outputId":"bdd5803f-9e5d-440d-b401-87111316b623"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["Download Europarl corpus for base model"],"metadata":{"id":"zAQ11tesH2Eh"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25671,"status":"ok","timestamp":1673708865362,"user":{"displayName":"Dan G","userId":"10633818666769653523"},"user_tz":-60},"id":"yiUFBOoBfcsi","outputId":"cb08a195-c490-4064-f8bc-aae991a6ba70"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Europarl\n","--2023-01-14 15:07:18--  https://object.pouta.csc.fi/OPUS-Europarl/v8/moses/de-en.txt.zip\n","Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n","Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 211805161 (202M) [application/zip]\n","Saving to: ‘de-en.txt.zip’\n","\n","de-en.txt.zip       100%[===================>] 201.99M  12.8MB/s    in 18s     \n","\n","2023-01-14 15:07:37 (11.4 MB/s) - ‘de-en.txt.zip’ saved [211805161/211805161]\n","\n","Archive:  de-en.txt.zip\n","  inflating: README                  \n","  inflating: LICENSE                 \n","  inflating: Europarl.de-en.de       \n","  inflating: Europarl.de-en.en       \n","  inflating: Europarl.de-en.xml      \n","/content\n"]}],"source":["! mkdir Europarl\n","%cd Europarl\n","! wget https://object.pouta.csc.fi/OPUS-Europarl/v7/moses/de-en.txt.zip\n","! unzip  de-en.txt.zip\n","%cd .."]},{"cell_type":"code","source":["! cp -R Europarl drive/MyDrive/NLP/"],"metadata":{"id":"yT7uHoui0hm8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! cp -R drive/MyDrive/NLP/Europarl Europarl"],"metadata":{"id":"4qB9RvZ9LRn9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Text preprocessing\n","\n","---\n","\n"],"metadata":{"id":"kZ-GzDYJ8lin"}},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","\n","SRC_FOLDER=Europarl\n","lang=de-en\n","src=en\n","tgt=de\n","\n","for l in $src $tgt; do\n","    awk 'NR%2== 1  {print $0}' $SRC_FOLDER/Europarl.$lang.$l > $SRC_FOLDER/Europarl2.$lang.$l\n","done\n","for l in $src $tgt; do\n","    rm $SRC_FOLDER/Europarl.$lang.$l\n","    mv $SRC_FOLDER/Europarl2.$lang.$l $SRC_FOLDER/Europarl.$lang.$l\n","done"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oOSXBxECrBOw","executionInfo":{"status":"ok","timestamp":1673709249993,"user_tz":-60,"elapsed":2073,"user":{"displayName":"Dan G","userId":"10633818666769653523"}},"outputId":"6fec5132-6d99-4f70-ad64-51f97b78d650"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","SRC_FOLDER=Europarl\n","TRG_FOLDER=EuroparlPrepered\n","SCRIPTS=mosesdecoder/scripts\n","TOKENIZER=$SCRIPTS/tokenizer/tokenizer.perl\n","CLEAN=$SCRIPTS/training/clean-corpus-n.perl\n","NORM_PUNC=$SCRIPTS/tokenizer/normalize-punctuation.perl\n","REM_NON_PRINT_CHAR=$SCRIPTS/tokenizer/remove-non-printing-char.perl\n","BPEROOT=subword-nmt/subword_nmt\n","BPE_TOKENS=32000\n","\n","lang=de-en\n","src=en\n","tgt=de\n","\n","echo \"splitting train, test and valid...\"\n","mkdir $TRG_FOLDER\n","mkdir $TRG_FOLDER/CODE\n","for l in $src $tgt; do\n","    awk '{if(NR%450<448) print $0;}' $SRC_FOLDER/Europarl.$lang.$l > $TRG_FOLDER/train.$l\n","    awk 'NR%500== 448  {print $0}' $SRC_FOLDER/Europarl.$lang.$l > $TRG_FOLDER/test.$l\n","    awk 'NR%500== 449  {print $0}' $SRC_FOLDER/Europarl.$lang.$l > $TRG_FOLDER/valid.$l\n","done\n","\n","echo \"preoprocessing train data...\"\n","for l in $src $tgt; do\n","    cat $TRG_FOLDER/train.$l | \\\n","      perl $NORM_PUNC $l | \\\n","      perl $REM_NON_PRINT_CHAR | \\\n","      perl $TOKENIZER -threads 8 -a -l $l >> $TRG_FOLDER/trainPREP.$l\n","done\n","\n","echo \"preoprocessing valid data...\"\n","for l in $src $tgt; do\n","    cat $TRG_FOLDER/valid.$l | \\\n","      perl $NORM_PUNC $l | \\\n","      perl $REM_NON_PRINT_CHAR | \\\n","      perl $TOKENIZER -threads 8 -a -l $l >> $TRG_FOLDER/validPREP.$l\n","done\n","\n","echo \"preoprocessing test data...\"\n","for l in $src $tgt; do\n","    cat $TRG_FOLDER/test.$l | \\\n","      perl $NORM_PUNC $l | \\\n","      perl $REM_NON_PRINT_CHAR | \\\n","      perl $TOKENIZER -threads 8 -a -l $l >> $TRG_FOLDER/testPREP.$l\n","done\n","\n","TRAIN=trainPREP.de-en\n","BPE_CODE=code\n","for l in $src $tgt; do\n","    cat $TRG_FOLDER/trainPREP.$l >> $TRG_FOLDER/$TRAIN\n","done\n","\n","echo \"learn_bpe.py on ${TRAIN}...\"\n","python $BPEROOT/learn_bpe.py -s $BPE_TOKENS < $TRG_FOLDER/$TRAIN > $TRG_FOLDER/CODE/$BPE_CODE\n","\n","for L in $src $tgt; do\n","    for f in trainPREP.$L validPREP.$L testPREP.$L; do\n","        echo \"apply_bpe.py to ${f}...\"\n","        python $BPEROOT/apply_bpe.py -c $TRG_FOLDER/CODE/$BPE_CODE < $TRG_FOLDER/$f > $TRG_FOLDER/CODE/bpe.$f\n","    done\n","done\n","mkdir $TRG_FOLDER/PREPERED\n","perl $CLEAN -ratio 1.5 $TRG_FOLDER/CODE/bpe.trainPREP $src $tgt $TRG_FOLDER/PREPERED/train 2 250\n","perl $CLEAN -ratio 1.5 $TRG_FOLDER/CODE/bpe.validPREP $src $tgt $TRG_FOLDER/PREPERED/valid 2 250\n","perl $CLEAN -ratio 1.5 $TRG_FOLDER/CODE/bpe.testPREP $src $tgt $TRG_FOLDER/PREPERED/test 2 250\n","\n","cp $TRG_FOLDER/CODE/code $TRG_FOLDER/PREPERED/code\n","cp -R EuroparlPrepered drive/MyDrive/NLP/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ACFGJ9Uf-tJg","executionInfo":{"status":"ok","timestamp":1672165863554,"user_tz":-60,"elapsed":472045,"user":{"displayName":"Dan G","userId":"10633818666769653523"}},"outputId":"d7c1ae4c-ba32-4920-a060-dded376c19ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["splitting train, test and valid...\n","preoprocessing train data...\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","preoprocessing valid data...\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","preoprocessing test data...\n","Tokenizer Version 1.1\n","Language: en\n","Number of threads: 8\n","Tokenizer Version 1.1\n","Language: de\n","Number of threads: 8\n","learn_bpe.py on trainPREP.de-en...\n","100% 32000/32000 [01:31<00:00, 347.94it/s]\n","apply_bpe.py to trainPREP.en...\n","apply_bpe.py to validPREP.en...\n","apply_bpe.py to testPREP.en...\n","apply_bpe.py to trainPREP.de...\n","apply_bpe.py to validPREP.de...\n","apply_bpe.py to testPREP.de...\n","clean-corpus.perl: processing EuroparlPrepered/CODE/bpe.trainPREP.en & .de to EuroparlPrepered/PREPERED/train, cutoff 2-250, ratio 1.5\n","..........(100000)..........(200000)..........(300000)..........(400000)..........(500000)..........(600000)..........(700000)..........(800000)..........(900000).......\n","Input sentences: 976202  Output sentences:  936039\n","clean-corpus.perl: processing EuroparlPrepered/CODE/bpe.validPREP.en & .de to EuroparlPrepered/PREPERED/valid, cutoff 2-250, ratio 1.5\n","\n","Input sentences: 1961  Output sentences:  1881\n","clean-corpus.perl: processing EuroparlPrepered/CODE/bpe.testPREP.en & .de to EuroparlPrepered/PREPERED/test, cutoff 2-250, ratio 1.5\n","\n","Input sentences: 1961  Output sentences:  1874\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["! cp -R drive/MyDrive/NLP/EuroparPrepered EuroparlPrepered"],"metadata":{"id":"6jh3cwxo2CFk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! mkdir EuroparlTokenized.en-de\n","! fairseq-preprocess \\\n","    --joined-dictionary \\\n","    --source-lang en --target-lang de \\\n","    --trainpref EuroparlPrepered/PREPERED/train --validpref EuroparlPrepered/PREPERED/valid --testpref EuroparlPrepered/PREPERED/test \\\n","    --destdir EuroparlTokenized.en-de\n","! cp -R EuroparlTokenized.en-de drive/MyDrive/NLP/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w3JeIX1grDwJ","executionInfo":{"status":"ok","timestamp":1672166264033,"user_tz":-60,"elapsed":349452,"user":{"displayName":"Dan G","userId":"10633818666769653523"}},"outputId":"0322f1f0-bfca-4ff0-dbdc-fe0d7e331f40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-12-27 18:31:56 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","2022-12-27 18:31:56 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='EuroparlTokenized.en-de', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='en', srcdict=None, suppress_crashes=False, target_lang='de', task='translation', tensorboard_logdir=None, testpref='EuroparlPrepered/PREPERED/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='EuroparlPrepered/PREPERED/train', use_plasma_view=False, user_dir=None, validpref='EuroparlPrepered/PREPERED/valid', wandb_project=None, workers=1)\n","2022-12-27 18:33:14 | INFO | fairseq_cli.preprocess | [en] Dictionary: 32104 types\n","2022-12-27 18:35:20 | INFO | fairseq_cli.preprocess | [en] EuroparlPrepered/PREPERED/train.en: 936039 sents, 28447927 tokens, 0.0% replaced (by <unk>)\n","2022-12-27 18:35:20 | INFO | fairseq_cli.preprocess | [en] Dictionary: 32104 types\n","2022-12-27 18:35:20 | INFO | fairseq_cli.preprocess | [en] EuroparlPrepered/PREPERED/valid.en: 1881 sents, 57060 tokens, 0.0% replaced (by <unk>)\n","2022-12-27 18:35:20 | INFO | fairseq_cli.preprocess | [en] Dictionary: 32104 types\n","2022-12-27 18:35:20 | INFO | fairseq_cli.preprocess | [en] EuroparlPrepered/PREPERED/test.en: 1874 sents, 56638 tokens, 0.0% replaced (by <unk>)\n","2022-12-27 18:35:20 | INFO | fairseq_cli.preprocess | [de] Dictionary: 32104 types\n","2022-12-27 18:37:39 | INFO | fairseq_cli.preprocess | [de] EuroparlPrepered/PREPERED/train.de: 936039 sents, 28582851 tokens, 0.0% replaced (by <unk>)\n","2022-12-27 18:37:39 | INFO | fairseq_cli.preprocess | [de] Dictionary: 32104 types\n","2022-12-27 18:37:39 | INFO | fairseq_cli.preprocess | [de] EuroparlPrepered/PREPERED/valid.de: 1881 sents, 57436 tokens, 0.0% replaced (by <unk>)\n","2022-12-27 18:37:39 | INFO | fairseq_cli.preprocess | [de] Dictionary: 32104 types\n","2022-12-27 18:37:39 | INFO | fairseq_cli.preprocess | [de] EuroparlPrepered/PREPERED/test.de: 1874 sents, 56727 tokens, 0.0% replaced (by <unk>)\n","2022-12-27 18:37:39 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to EuroparlTokenized.en-de\n"]}]},{"cell_type":"code","source":["! cp -R drive/MyDrive/NLP/EuroparlTokenized.en-de EuroparlTokenized.en-de"],"metadata":{"id":"8Ee1SmBmZjM5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! mkdir -p EuroparlModel\n","! mkdir -p EuroparlModel/transformer"],"metadata":{"id":"EQRcum4GV_FR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! CUDA_VISIBLE_DEVICES=0 fairseq-train --fp16 drive/MyDrive/NLP/EuroparlTokenized.en-de \\\n","    --source-lang en --target-lang de \\\n","    --arch transformer_wmt_en_de 6 \\\n","    --dropout 0.3 --weight-decay 0.0 \\\n","    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n","    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n","    --lr 0.001 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n","    --max-tokens 3584 --update-freq 16 \\\n","    --max-update 11000 \\\n","    --save-dir drive/MyDrive/NLP/EuroparlModel/transformer \\\n","    --wandb-project \"Uczenie modelu podstawowego\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"amnbtB4lv4_m","outputId":"463d4e44-f07e-4cc5-b492-508f235d1954","executionInfo":{"status":"ok","timestamp":1673001894528,"user_tz":-60,"elapsed":955996,"user":{"displayName":"Dan G","userId":"10633818666769653523"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-06 10:29:00 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","2023-01-06 10:29:01 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': 'Uczenie modelu podstawowego', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3584, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3584, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 11000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'drive/MyDrive/NLP/EuroparlModel/transformer', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_wmt_en_de', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_wmt_en_de', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='drive/MyDrive/NLP/EuroparlTokenized.en-de', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=3584, max_tokens_valid=3584, max_update=11000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='drive/MyDrive/NLP/EuroparlModel/transformer', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang='en', stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang='de', task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[16], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project='Uczenie modelu podstawowego', warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'drive/MyDrive/NLP/EuroparlTokenized.en-de', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.001]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2023-01-06 10:29:01 | INFO | fairseq.tasks.translation | [en] dictionary: 32104 types\n","2023-01-06 10:29:01 | INFO | fairseq.tasks.translation | [de] dictionary: 32104 types\n","2023-01-06 10:29:02 | INFO | fairseq_cli.train | TransformerModel(\n","  (encoder): TransformerEncoderBase(\n","    (dropout_module): FairseqDropout()\n","    (embed_tokens): Embedding(32104, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (decoder): TransformerDecoderBase(\n","    (dropout_module): FairseqDropout()\n","    (embed_tokens): Embedding(32104, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (output_projection): Linear(in_features=512, out_features=32104, bias=False)\n","  )\n",")\n","2023-01-06 10:29:02 | INFO | fairseq_cli.train | task: TranslationTask\n","2023-01-06 10:29:02 | INFO | fairseq_cli.train | model: TransformerModel\n","2023-01-06 10:29:02 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n","2023-01-06 10:29:02 | INFO | fairseq_cli.train | num. shared model params: 79,477,760 (num. trained: 79,477,760)\n","2023-01-06 10:29:02 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n","2023-01-06 10:29:02 | INFO | fairseq.data.data_utils | loaded 1,881 examples from: drive/MyDrive/NLP/EuroparlTokenized.en-de/valid.en-de.en\n","2023-01-06 10:29:02 | INFO | fairseq.data.data_utils | loaded 1,881 examples from: drive/MyDrive/NLP/EuroparlTokenized.en-de/valid.en-de.de\n","2023-01-06 10:29:02 | INFO | fairseq.tasks.translation | drive/MyDrive/NLP/EuroparlTokenized.en-de valid en-de 1881 examples\n","2023-01-06 10:29:04 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n","2023-01-06 10:29:04 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight\n","2023-01-06 10:29:04 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n","2023-01-06 10:29:04 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.756 GB ; name = Tesla T4                                \n","2023-01-06 10:29:04 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n","2023-01-06 10:29:04 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n","2023-01-06 10:29:04 | INFO | fairseq_cli.train | max tokens per device = 3584 and max sentences per device = None\n","2023-01-06 10:29:04 | INFO | fairseq.trainer | Preparing to load checkpoint drive/MyDrive/NLP/EuroparlModel/transformer/checkpoint_last.pt\n","2023-01-06 10:29:07 | INFO | fairseq.trainer | Loaded checkpoint drive/MyDrive/NLP/EuroparlModel/transformer/checkpoint_last.pt (epoch 20 @ 10533 updates)\n","2023-01-06 10:29:07 | INFO | fairseq.trainer | loading train data for epoch 20\n","2023-01-06 10:29:07 | INFO | fairseq.data.data_utils | loaded 936,039 examples from: drive/MyDrive/NLP/EuroparlTokenized.en-de/train.en-de.en\n","2023-01-06 10:29:09 | INFO | fairseq.data.data_utils | loaded 936,039 examples from: drive/MyDrive/NLP/EuroparlTokenized.en-de/train.en-de.de\n","2023-01-06 10:29:09 | INFO | fairseq.tasks.translation | drive/MyDrive/NLP/EuroparlTokenized.en-de train en-de 936039 examples\n","2023-01-06 10:29:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 555\n","epoch 020:   0% 0/555 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdaniel-gorniak-stud\u001b[0m (\u001b[33mnlppw\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230106_102910-1d6boa8s\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtransformer\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nlppw/Uczenie%20modelu%20podstawowego\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/nlppw/Uczenie%20modelu%20podstawowego/runs/1d6boa8s\u001b[0m\n","2023-01-06 10:29:11 | INFO | fairseq.trainer | begin training epoch 20\n","2023-01-06 10:29:11 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 020:   2% 10/555 [00:21<16:57,  1.87s/it]2023-01-06 10:29:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0\n","epoch 020:  84% 467/555 [15:17<03:04,  2.09s/it, loss=3.767, nll_loss=2.075, ppl=4.21, wps=26252.5, ups=0.51, wpb=51587.5, bsz=1714.3, num_updates=10900, lr=0.000605783, gnorm=0.324, loss_scale=8, train_wall=192, gb_free=11.3, wall=727]2023-01-06 10:44:29 | INFO | fairseq_cli.train | Stopping training due to num_updates: 11000 >= max_update: 11000\n","2023-01-06 10:44:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 020 | valid on 'valid' subset:   0% 0/25 [00:00<?, ?it/s]\u001b[A\n","epoch 020 | valid on 'valid' subset:   4% 1/25 [00:00<00:06,  3.96it/s]\u001b[A\n","epoch 020 | valid on 'valid' subset:  12% 3/25 [00:00<00:02,  8.64it/s]\u001b[A\n","epoch 020 | valid on 'valid' subset:  24% 6/25 [00:00<00:01, 14.05it/s]\u001b[A\n","epoch 020 | valid on 'valid' subset:  36% 9/25 [00:00<00:00, 17.34it/s]\u001b[A\n","epoch 020 | valid on 'valid' subset:  48% 12/25 [00:00<00:00, 19.56it/s]\u001b[A\n","epoch 020 | valid on 'valid' subset:  60% 15/25 [00:00<00:00, 21.34it/s]\u001b[A\n","epoch 020 | valid on 'valid' subset:  72% 18/25 [00:01<00:00, 22.30it/s]\u001b[A\n","epoch 020 | valid on 'valid' subset:  84% 21/25 [00:01<00:00, 22.41it/s]\u001b[A\n","epoch 020 | valid on 'valid' subset:  96% 24/25 [00:01<00:00, 23.75it/s]\u001b[A\n","                                                                        \u001b[A2023-01-06 10:44:30 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 3.536 | nll_loss 1.747 | ppl 3.36 | wps 53503 | wpb 2297.4 | bsz 75.2 | num_updates 11000 | best_loss 3.536\n","2023-01-06 10:44:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 11000 updates\n","2023-01-06 10:44:30 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/NLP/EuroparlModel/transformer/checkpoint_best.pt\n","2023-01-06 10:44:36 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/NLP/EuroparlModel/transformer/checkpoint_best.pt\n","2023-01-06 10:44:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint drive/MyDrive/NLP/EuroparlModel/transformer/checkpoint_best.pt (epoch 20 @ 11000 updates, score 3.536) (writing took 11.002745671999946 seconds)\n","2023-01-06 10:44:41 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)\n","2023-01-06 10:44:41 | INFO | train | epoch 020 | loss 3.757 | nll_loss 2.063 | ppl 4.18 | wps 25905.2 | ups 0.5 | wpb 51482.3 | bsz 1681.6 | num_updates 11000 | lr 0.000603023 | gnorm 0.321 | loss_scale 8 | train_wall 895 | gb_free 11.3 | wall 937\n","2023-01-06 10:44:41 | INFO | fairseq_cli.train | done training in 931.5 seconds\n"]}]},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","CHECKPOINT_DIR=../drive/MyDrive/NLP/EuroparlModel/transformer\n","bash examples/backtranslation/sacrebleu.sh \\\n","    wmt17 \\\n","    en-de \\\n","    ../drive/MyDrive/NLP/EuroparlTokenized.en-de \\\n","    ../drive/MyDrive/NLP/EuroparlPrepered/CODE/code \\\n","    $CHECKPOINT_DIR/checkpoint_best.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXzobJYhkD1e","executionInfo":{"status":"ok","timestamp":1673002144713,"user_tz":-60,"elapsed":57001,"user":{"displayName":"Dan G","userId":"10633818666769653523"}},"outputId":"29ae7f8f-fcab-48e5-f588-590e7cef4b61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-06 10:48:10 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","2023-01-06 10:48:12 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../drive/MyDrive/NLP/EuroparlModel/transformer/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 8000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 8000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 1024, 'input': 'source.txt'}, 'model': None, 'task': {'_name': 'translation', 'data': '../drive/MyDrive/NLP/EuroparlTokenized.en-de', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2023-01-06 10:48:12 | INFO | fairseq.tasks.translation | [en] dictionary: 32104 types\n","2023-01-06 10:48:12 | INFO | fairseq.tasks.translation | [de] dictionary: 32104 types\n","2023-01-06 10:48:12 | INFO | fairseq_cli.interactive | loading model(s) from ../drive/MyDrive/NLP/EuroparlModel/transformer/checkpoint_best.pt\n","2023-01-06 10:48:16 | INFO | fairseq_cli.interactive | Sentence buffer size: 1024\n","2023-01-06 10:48:16 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2023-01-06 10:48:16 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2023-01-06 10:49:01 | INFO | fairseq_cli.interactive | Total time: 49.617 seconds; translation time: 32.917\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 20.1,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1\",\n"," \"verbose_score\": \"52.1/25.4/14.4/8.5 (BP = 1.000 ratio = 1.062 hyp_len = 65106 ref_len = 61287)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.3.1\"\n","}\n","\u001b[0m"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","CHECKPOINT_DIR=../drive/MyDrive/NLP/EuroparlModel/transformer\n","bash examples/backtranslation/sacrebleu.sh \\\n","    wmt08/europarl \\\n","    en-de \\\n","    ../drive/MyDrive/NLP/EuroparlTokenized.en-de \\\n","    ../drive/MyDrive/NLP/EuroparlPrepered/CODE/code \\\n","    $CHECKPOINT_DIR/checkpoint_best.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4clxHQsnltBD","executionInfo":{"status":"ok","timestamp":1673002051560,"user_tz":-60,"elapsed":45382,"user":{"displayName":"Dan G","userId":"10633818666769653523"}},"outputId":"8058f9b0-a077-4482-a29f-ed9785a47bc2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-06 10:46:48 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","2023-01-06 10:46:50 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../drive/MyDrive/NLP/EuroparlModel/transformer/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 8000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 8000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 1024, 'input': 'source.txt'}, 'model': None, 'task': {'_name': 'translation', 'data': '../drive/MyDrive/NLP/EuroparlTokenized.en-de', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2023-01-06 10:46:50 | INFO | fairseq.tasks.translation | [en] dictionary: 32104 types\n","2023-01-06 10:46:50 | INFO | fairseq.tasks.translation | [de] dictionary: 32104 types\n","2023-01-06 10:46:50 | INFO | fairseq_cli.interactive | loading model(s) from ../drive/MyDrive/NLP/EuroparlModel/transformer/checkpoint_best.pt\n","2023-01-06 10:46:54 | INFO | fairseq_cli.interactive | Sentence buffer size: 1024\n","2023-01-06 10:46:54 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2023-01-06 10:46:54 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2023-01-06 10:47:28 | INFO | fairseq_cli.interactive | Total time: 38.497 seconds; translation time: 25.749\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 27.7,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1\",\n"," \"verbose_score\": \"57.2/32.5/21.4/14.8 (BP = 1.000 ratio = 1.019 hyp_len = 57932 ref_len = 56829)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.3.1\"\n","}\n","\u001b[0m"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"wNl5UQkTsC0m"},"source":["\n","\n","> BACKTRANSLATION\n","\n"]},{"cell_type":"markdown","source":["Prepare paraller corpora"],"metadata":{"id":"1whl35sFXcGe"}},{"cell_type":"code","source":["! cp drive/MyDrive/NLP/scripts/prepare-wmt18en2de.sh /content/fairseq/examples/backtranslation/"],"metadata":{"id":"A8VwIq-IXjPX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%shell\n","cd fairseq/examples/backtranslation/\n","bash prepare-wmt18en2de.sh"],"metadata":{"id":"O8r6oGfdXk5k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! cp /content/fairseq/examples/backtranslation/prepare-wmt18en2de.sh drive/MyDrive/NLP/scripts/"],"metadata":{"id":"0Bbwt_S0Xm5D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%shell\n","cd ./fairseq/\n","TEXT=examples/backtranslation/wmt18_en_de\n","fairseq-preprocess \\\n","    --joined-dictionary \\\n","    --source-lang en --target-lang de \\\n","    --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\n","    --destdir data-bin/wmt18_en_de --thresholdtgt 0 --thresholdsrc 0 \\\n","    --workers 20"],"metadata":{"id":"ysAEi2EkXoSI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! cp ./fairseq/examples/backtranslation/wmt18_en_de/code ./fairseq/data-bin/wmt18_en_de/code"],"metadata":{"id":"Q7-c4PX6Xo32"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! cp -R /content/fairseq/data-bin drive/MyDrive/NLP/data-bin"],"metadata":{"id":"E3J-w6YIXq5Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train intermidiete model"],"metadata":{"id":"pSmvdAcr4RBG"}},{"cell_type":"code","source":["! cp -R drive/MyDrive/NLP/data-bin /content/fairseq/data-bin"],"metadata":{"id":"DoGdKXV7Xx2n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","CHECKPOINT_DIR=../drive/MyDrive/NLP/checkpoints_de_en_parallel\n","fairseq-train --fp16 \\\n","    data-bin/wmt18_en_de \\\n","    --source-lang de --target-lang en \\\n","    --arch transformer_wmt_en_de --share-all-embeddings \\\n","    --dropout 0.3 --weight-decay 0.0 \\\n","    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n","    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n","    --lr 0.001 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n","    --max-tokens 3584 --update-freq 16 \\\n","    --max-update 15000 \\\n","    --save-dir $CHECKPOINT_DIR \\\n","    --wandb-project \"transformer_wmt_de_en\""],"metadata":{"id":"mfMZrowOX10t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["evaluate model"],"metadata":{"id":"LF3BbWvZX5eb"}},{"cell_type":"code","source":["! cp drive/MyDrive/NLP/scripts/sacrebleu.sh /content/fairseq/examples/backtranslation/"],"metadata":{"id":"FzewpwzTX2W6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","CHECKPOINT_DIR=../drive/MyDrive/NLP/checkpoints_de_en_parallel\n","bash examples/backtranslation/sacrebleu.sh \\\n","    wmt17 \\\n","    de-en \\\n","    data-bin/wmt18_en_de \\\n","    data-bin/wmt18_en_de/code \\\n","    $CHECKPOINT_DIR/checkpoint_best.pt"],"metadata":{"id":"gcwq_mSfX7BX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","CHECKPOINT_DIR=../drive/MyDrive/NLP/checkpoints_de_en_parallel\n","bash examples/backtranslation/sacrebleu.sh \\\n","    wmt08/europarl \\\n","    de-en \\\n","    data-bin/wmt18_en_de \\\n","    data-bin/wmt18_en_de/code \\\n","    $CHECKPOINT_DIR/checkpoint_best.pt"],"metadata":{"id":"7zlFBGqyX8in"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! cp /content/fairseq/examples/backtranslation/sacrebleu.sh drive/MyDrive/NLP/scripts/"],"metadata":{"id":"hAWtVpk4YDwh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["prepare monolingual data"],"metadata":{"id":"i2jpuj69YFts"}},{"cell_type":"code","source":["! cp drive/MyDrive/NLP/scripts/prepare-de-monolingual.sh /content/fairseq/examples/backtranslation/"],"metadata":{"id":"K3Km0LeaYGLw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! cp -r /content/fairseq/data-bin/wmt18_en_de /content/fairseq/examples/backtranslation"],"metadata":{"id":"FC2FJD3MYJ1c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/examples/backtranslation/\n","bash prepare-de-monolingual.sh\n","cd ../.."],"metadata":{"id":"p2xtmhu7YLfl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! cp /content/fairseq/examples/backtranslation/prepare-de-monolingual.sh drive/MyDrive/NLP/scripts/"],"metadata":{"id":"nR_gb1ehYNU4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","TEXT=examples/backtranslation/wmt18_de_mono\n","for SHARD in $(seq -f \"%02g\" 0 24); do \\\n","    fairseq-preprocess \\\n","        --only-source \\\n","        --source-lang de --target-lang en \\\n","        --joined-dictionary \\\n","        --srcdict data-bin/wmt18_en_de/dict.de.txt \\\n","        --testpref $TEXT/bpe.monolingual.dedup.${SHARD} \\\n","        --destdir data-bin/wmt18_de_mono/shard${SHARD} \\\n","        --workers 20; \\\n","    cp data-bin/wmt18_en_de/dict.en.txt data-bin/wmt18_de_mono/shard${SHARD}/; \\\n","done"],"metadata":{"id":"DihvIbe5YO1b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! cp -R /content/fairseq/data-bin/wmt18_de_mono drive/MyDrive/NLP/data-bin/wmt18_de_mono"],"metadata":{"id":"FhibQ6DFYRGw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["beam search"],"metadata":{"id":"WyG7Sx3tYRba"}},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","mkdir backtranslation_output\n","for SHARD in $(seq -f \"%02g\" 0 24); do \\\n","    fairseq-generate --fp16 \\\n","        data-bin/wmt18_de_mono/shard${SHARD} \\\n","        --path ../drive/MyDrive/NLP/checkpoints_de_en_parallel/checkpoint_best.pt \\\n","        --skip-invalid-size-inputs-valid-test \\\n","        --max-tokens 4096 \\\n","        --sampling --beam 5 \\\n","        --nbest 5 \\\n","    > backtranslation_output/sampling.shard${SHARD}.out; \\\n","done"],"metadata":{"id":"sTYUsdu2YSoq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! cp -R /content/fairseq/backtranslation_output drive/MyDrive/NLP/backtranslation_output_beam"],"metadata":{"id":"aW9niHneYV4B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["top10"],"metadata":{"id":"YqLI6cVSYW8a"}},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","mkdir backtranslation_output\n","for SHARD in $(seq -f \"%02g\" 0 24); do \\\n","    fairseq-generate --fp16 \\\n","        data-bin/wmt18_de_mono/shard${SHARD} \\\n","        --path ../drive/MyDrive/NLP/checkpoints_de_en_parallel/checkpoint_best.pt \\\n","        --skip-invalid-size-inputs-valid-test \\\n","        --max-tokens 4096 \\\n","        --sampling --beam 1 \\\n","        --sampling-topk 10 \\\n","    > backtranslation_output/sampling.shard${SHARD}.out; \\\n","done"],"metadata":{"id":"0m_MijGxYWLs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! cp -R /content/fairseq/backtranslation_output drive/MyDrive/NLP/backtranslation_output_top10"],"metadata":{"id":"aicOrGA1YdvG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Combaining monolingual data with parallel data"],"metadata":{"id":"uAVzEnGkYfvB"}},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","python examples/backtranslation/extract_bt_data.py \\\n","    --minlen 1 --maxlen 250 --ratio 1.5 \\\n","    --output backtranslation_output/bt_data --srclang en --tgtlang de \\\n","    backtranslation_output/sampling.shard*.out"],"metadata":{"id":"yavRt0VeYv7j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! wc -l fairseq/backtranslation_output/bt_data.{en,de}"],"metadata":{"id":"87MfAdbmYzjX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","TEXT=backtranslation_output\n","fairseq-preprocess \\\n","    --source-lang en --target-lang de \\\n","    --joined-dictionary \\\n","    --srcdict data-bin/wmt18_en_de/dict.en.txt \\\n","    --trainpref $TEXT/bt_data \\\n","    --destdir data-bin/wmt18_en_de_bt_top10 \\\n","    --workers 20"],"metadata":{"id":"c0ShEqMMYzs_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","PARA_DATA=$(readlink -f data-bin/wmt18_en_de)\n","BT_DATA=$(readlink -f data-bin/wmt18_en_de_bt_top10)\n","COMB_DATA=data-bin/wmt18_en_de_para_plus_bt_top10\n","mkdir -p $COMB_DATA\n","for LANG in en de; do \\\n","    ln -s ${PARA_DATA}/dict.$LANG.txt ${COMB_DATA}/dict.$LANG.txt; \\\n","    for EXT in bin idx; do \\\n","        ln -s ${PARA_DATA}/train.en-de.$LANG.$EXT ${COMB_DATA}/train.en-de.$LANG.$EXT; \\\n","        ln -s ${BT_DATA}/train.en-de.$LANG.$EXT ${COMB_DATA}/train1.en-de.$LANG.$EXT; \\\n","        ln -s ${PARA_DATA}/valid.en-de.$LANG.$EXT ${COMB_DATA}/valid.en-de.$LANG.$EXT; \\\n","        ln -s ${PARA_DATA}/test.en-de.$LANG.$EXT ${COMB_DATA}/test.en-de.$LANG.$EXT; \\\n","    done; \\\n","done"],"metadata":{"id":"yB4LBF9UY4s2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! cp -R /content/fairseq/data-bin/wmt18_en_de_para_plus_bt_top10 drive/MyDrive/NLP/wmt18_en_de_para_plus_bt_top10"],"metadata":{"id":"9HhidFU5Y6Rp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! cp -R /content/fairseq/data-bin/wmt18_en_de_bt_top10 drive/MyDrive/NLP/wmt18_en_de_bt_top10"],"metadata":{"id":"z85sT4gcY7kt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train an English-German model over the combined parallel + BT data"],"metadata":{"id":"Xfvi91WEY9fG"}},{"cell_type":"code","source":["! cp -R drive/MyDrive/NLP/data-bin /content/fairseq/data-bin"],"metadata":{"id":"u7METYArY9vU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","CHECKPOINT_DIR=../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam\n","fairseq-train --fp16 \\\n","    data-bin/wmt18_en_de_para_plus_bt_beam \\\n","    --upsample-primary 1 \\\n","    --source-lang en --target-lang de \\\n","    --arch transformer_wmt_en_de --share-all-embeddings \\\n","    --dropout 0.3 --weight-decay 0.0 \\\n","    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n","    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n","    --lr 0.0007 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n","    --max-tokens 3584 --update-freq 16 \\\n","    --max-update 15000 \\\n","    --save-dir $CHECKPOINT_DIR \\\n","    --wandb-project \"transformer_wmt_en_de_beam\""],"metadata":{"id":"xkZKd3tQZA1H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","CHECKPOINT_DIR=../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10\n","fairseq-train --fp16 \\\n","    data-bin/wmt18_en_de_para_plus_bt_top10 \\\n","    --upsample-primary 1 \\\n","    --source-lang en --target-lang de \\\n","    --arch transformer_wmt_en_de --share-all-embeddings \\\n","    --dropout 0.3 --weight-decay 0.0 \\\n","    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n","    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n","    --lr 0.0007 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n","    --max-tokens 3584 --update-freq 16 \\\n","    --max-update 15000 \\\n","    --save-dir $CHECKPOINT_DIR \\\n","    --wandb-project \"transformer_wmt_en_de_top10\""],"metadata":{"id":"BQbpdTiAZDCr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training with backtranslation"],"metadata":{"id":"PhFcdvV7-MYj"}},{"cell_type":"code","source":["! cp -R drive/MyDrive/NLP/data-bin /content/fairseq/data-bin"],"metadata":{"id":"Y45MTk2T-LSE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! cp drive/MyDrive/NLP/sacrebleu.sh /content/fairseq/examples/backtranslation/"],"metadata":{"id":"7_gCZBTvM6W4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Beam"],"metadata":{"id":"UXNgza-fZpcP"}},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","CHECKPOINT_DIR=../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam\n","fairseq-train --fp16 \\\n","    data-bin/wmt18_en_de_para_plus_bt_beam \\\n","    --upsample-primary 1 \\\n","    --source-lang en --target-lang de \\\n","    --arch transformer_wmt_en_de --share-all-embeddings \\\n","    --dropout 0.3 --weight-decay 0.0 \\\n","    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n","    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n","    --lr 0.0007 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n","    --max-tokens 3584 --update-freq 16 \\\n","    --max-update 11000 \\\n","    --save-dir $CHECKPOINT_DIR \\\n","    --wandb-project \"transformer_wmt_en_de_beam\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bexOcXJO-R4d","outputId":"5482368a-5abd-4e74-cac5-e80d822d8973","executionInfo":{"status":"ok","timestamp":1672946531885,"user_tz":-60,"elapsed":5982576,"user":{"displayName":"Dan G","userId":"10633818666769653523"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-05 17:42:31 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","2023-01-05 17:42:33 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': 'transformer_wmt_en_de_beam', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3584, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3584, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 11000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0007], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_wmt_en_de', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_wmt_en_de', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt18_en_de_para_plus_bt_beam', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0007], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=3584, max_tokens_valid=3584, max_update=11000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang='en', stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang='de', task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[16], update_ordered_indices_seed=False, upsample_primary=1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project='transformer_wmt_en_de_beam', warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/wmt18_en_de_para_plus_bt_beam', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': 1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0007]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2023-01-05 17:42:35 | INFO | fairseq.tasks.translation | [en] dictionary: 32232 types\n","2023-01-05 17:42:35 | INFO | fairseq.tasks.translation | [de] dictionary: 32232 types\n","2023-01-05 17:42:36 | INFO | fairseq_cli.train | TransformerModel(\n","  (encoder): TransformerEncoderBase(\n","    (dropout_module): FairseqDropout()\n","    (embed_tokens): Embedding(32232, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (decoder): TransformerDecoderBase(\n","    (dropout_module): FairseqDropout()\n","    (embed_tokens): Embedding(32232, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (output_projection): Linear(in_features=512, out_features=32232, bias=False)\n","  )\n",")\n","2023-01-05 17:42:36 | INFO | fairseq_cli.train | task: TranslationTask\n","2023-01-05 17:42:36 | INFO | fairseq_cli.train | model: TransformerModel\n","2023-01-05 17:42:36 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n","2023-01-05 17:42:36 | INFO | fairseq_cli.train | num. shared model params: 79,543,296 (num. trained: 79,543,296)\n","2023-01-05 17:42:36 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n","2023-01-05 17:42:38 | INFO | fairseq.data.data_utils | loaded 1,843 examples from: data-bin/wmt18_en_de_para_plus_bt_beam/valid.en-de.en\n","2023-01-05 17:42:40 | INFO | fairseq.data.data_utils | loaded 1,843 examples from: data-bin/wmt18_en_de_para_plus_bt_beam/valid.en-de.de\n","2023-01-05 17:42:40 | INFO | fairseq.tasks.translation | data-bin/wmt18_en_de_para_plus_bt_beam valid en-de 1843 examples\n","2023-01-05 17:42:42 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n","2023-01-05 17:42:42 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight\n","2023-01-05 17:42:42 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n","2023-01-05 17:42:42 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.756 GB ; name = Tesla T4                                \n","2023-01-05 17:42:42 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n","2023-01-05 17:42:42 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n","2023-01-05 17:42:42 | INFO | fairseq_cli.train | max tokens per device = 3584 and max sentences per device = None\n","2023-01-05 17:42:42 | INFO | fairseq.trainer | Preparing to load checkpoint ../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam/checkpoint_last.pt\n","2023-01-05 17:43:00 | INFO | fairseq.trainer | Loaded checkpoint ../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam/checkpoint_last.pt (epoch 5 @ 8111 updates)\n","2023-01-05 17:43:00 | INFO | fairseq.trainer | loading train data for epoch 5\n","2023-01-05 17:43:05 | INFO | fairseq.data.data_utils | loaded 1,838,523 examples from: data-bin/wmt18_en_de_para_plus_bt_beam/train.en-de.en\n","2023-01-05 17:43:10 | INFO | fairseq.data.data_utils | loaded 1,838,523 examples from: data-bin/wmt18_en_de_para_plus_bt_beam/train.en-de.de\n","2023-01-05 17:43:10 | INFO | fairseq.tasks.translation | data-bin/wmt18_en_de_para_plus_bt_beam train en-de 1838523 examples\n","2023-01-05 17:43:15 | INFO | fairseq.data.data_utils | loaded 1,792,666 examples from: data-bin/wmt18_en_de_para_plus_bt_beam/train1.en-de.en\n","2023-01-05 17:43:21 | INFO | fairseq.data.data_utils | loaded 1,792,666 examples from: data-bin/wmt18_en_de_para_plus_bt_beam/train1.en-de.de\n","2023-01-05 17:43:21 | INFO | fairseq.tasks.translation | data-bin/wmt18_en_de_para_plus_bt_beam train1 en-de 1792666 examples\n","2023-01-05 17:43:22 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2030\n","epoch 005:   0% 0/2030 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdaniel-gorniak-stud\u001b[0m (\u001b[33mnlppw\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/fairseq/wandb/run-20230105_174323-t2aburh6\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcheckpoints_en_de_parallel_bt_beam\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nlppw/transformer_wmt_en_de_beam\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/nlppw/transformer_wmt_en_de_beam/runs/t2aburh6\u001b[0m\n","2023-01-05 17:43:24 | INFO | fairseq.trainer | begin training epoch 5\n","2023-01-05 17:43:24 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 005:  53% 1071/2030 [36:15<32:32,  2.04s/it, loss=4.235, nll_loss=2.595, ppl=6.04, wps=25505.3, ups=0.49, wpb=51726.9, bsz=1742.2, num_updates=9100, lr=0.000464095, gnorm=0.351, loss_scale=16, train_wall=198, gb_free=11.3, wall=2050]2023-01-05 18:19:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0\n","epoch 005: 100% 2029/2030 [1:08:46<00:02,  2.04s/it, loss=4.207, nll_loss=2.566, ppl=5.92, wps=25556.3, ups=0.49, wpb=52019.9, bsz=1775.9, num_updates=10100, lr=0.000440522, gnorm=0.35, loss_scale=16, train_wall=199, gb_free=11.2, wall=4087]2023-01-05 18:52:09 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 005 | valid on 'valid' subset:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:   4% 1/24 [00:00<00:04,  5.12it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  17% 4/24 [00:00<00:01, 13.06it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  29% 7/24 [00:00<00:01, 16.82it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  42% 10/24 [00:00<00:00, 18.25it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  54% 13/24 [00:00<00:00, 20.51it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  67% 16/24 [00:00<00:00, 21.34it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  79% 19/24 [00:00<00:00, 21.96it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  92% 22/24 [00:01<00:00, 22.58it/s]\u001b[A\n","                                                                        \u001b[A2023-01-05 18:52:11 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 3.912 | nll_loss 2.149 | ppl 4.44 | wps 54587.8 | wpb 2345.4 | bsz 76.8 | num_updates 10140 | best_loss 3.912\n","2023-01-05 18:52:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 10140 updates\n","2023-01-05 18:52:11 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam/checkpoint5.pt\n","2023-01-05 18:52:17 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam/checkpoint5.pt\n","2023-01-05 18:52:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam/checkpoint5.pt (epoch 5 @ 10140 updates, score 3.912) (writing took 25.59343691899994 seconds)\n","2023-01-05 18:52:36 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n","2023-01-05 18:52:36 | INFO | train | epoch 005 | loss 4.232 | nll_loss 2.592 | ppl 6.03 | wps 25357.9 | ups 0.49 | wpb 51852.8 | bsz 1788.6 | num_updates 10140 | lr 0.000439652 | gnorm 0.353 | loss_scale 16 | train_wall 4024 | gb_free 11.3 | wall 4194\n","2023-01-05 18:52:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2030\n","epoch 006:   0% 0/2030 [00:00<?, ?it/s]2023-01-05 18:52:36 | INFO | fairseq.trainer | begin training epoch 6\n","2023-01-05 18:52:36 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 006:   5% 105/2030 [03:34<1:05:15,  2.03s/it, loss=4.182, nll_loss=2.537, ppl=5.8, wps=22334.7, ups=0.43, wpb=51614.1, bsz=1777.6, num_updates=10200, lr=0.000438357, gnorm=0.353, loss_scale=16, train_wall=198, gb_free=11.3, wall=4318]2023-01-05 18:56:12 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0\n","epoch 006:  42% 860/2030 [29:08<39:48,  2.04s/it, loss=4.164, nll_loss=2.518, ppl=5.73, wps=25475.3, ups=0.49, wpb=51757.4, bsz=1760.6, num_updates=10900, lr=0.000424048, gnorm=0.342, loss_scale=16, train_wall=198, gb_free=11.2, wall=5743]2023-01-05 19:21:47 | INFO | fairseq_cli.train | Stopping training due to num_updates: 11000 >= max_update: 11000\n","2023-01-05 19:21:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 006 | valid on 'valid' subset:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:   8% 2/24 [00:00<00:01, 13.83it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  17% 4/24 [00:00<00:01, 15.63it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  29% 7/24 [00:00<00:00, 19.36it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  42% 10/24 [00:00<00:00, 20.73it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  54% 13/24 [00:00<00:00, 22.52it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  67% 16/24 [00:00<00:00, 22.99it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  79% 19/24 [00:00<00:00, 22.94it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  92% 22/24 [00:01<00:00, 22.29it/s]\u001b[A\n","                                                                        \u001b[A2023-01-05 19:21:49 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 3.89 | nll_loss 2.124 | ppl 4.36 | wps 54015.6 | wpb 2345.4 | bsz 76.8 | num_updates 11000 | best_loss 3.89\n","2023-01-05 19:21:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 11000 updates\n","2023-01-05 19:21:49 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam/checkpoint_best.pt\n","2023-01-05 19:21:54 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam/checkpoint_best.pt\n","2023-01-05 19:21:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam/checkpoint_best.pt (epoch 6 @ 11000 updates, score 3.89) (writing took 10.11603377099982 seconds)\n","2023-01-05 19:21:59 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)\n","2023-01-05 19:21:59 | INFO | train | epoch 006 | loss 4.167 | nll_loss 2.521 | ppl 5.74 | wps 25315.7 | ups 0.49 | wpb 51881.2 | bsz 1778.7 | num_updates 11000 | lr 0.000422116 | gnorm 0.341 | loss_scale 16 | train_wall 1707 | gb_free 11.2 | wall 5957\n","2023-01-05 19:21:59 | INFO | fairseq_cli.train | done training in 5916.6 seconds\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","CHECKPOINT_DIR=../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam\n","bash examples/backtranslation/sacrebleu.sh \\\n","    wmt17 \\\n","    en-de \\\n","    data-bin/wmt18_en_de \\\n","    data-bin/wmt18_en_de/code \\\n","    $CHECKPOINT_DIR/checkpoint_best.pt"],"metadata":{"id":"2f8n8ICTQDPu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672949636062,"user_tz":-60,"elapsed":51490,"user":{"displayName":"Dan G","userId":"10633818666769653523"}},"outputId":"82fcd2fd-20fc-4ad1-c852-fbb528f7cfe1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-05 20:13:08 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","2023-01-05 20:13:09 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 8000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 8000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 1024, 'input': 'source.txt'}, 'model': None, 'task': {'_name': 'translation', 'data': 'data-bin/wmt18_en_de', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2023-01-05 20:13:09 | INFO | fairseq.tasks.translation | [en] dictionary: 32232 types\n","2023-01-05 20:13:09 | INFO | fairseq.tasks.translation | [de] dictionary: 32232 types\n","2023-01-05 20:13:09 | INFO | fairseq_cli.interactive | loading model(s) from ../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam/checkpoint_best.pt\n","2023-01-05 20:13:14 | INFO | fairseq_cli.interactive | Sentence buffer size: 1024\n","2023-01-05 20:13:14 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2023-01-05 20:13:14 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2023-01-05 20:13:54 | INFO | fairseq_cli.interactive | Total time: 44.602 seconds; translation time: 29.750\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 23.4,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1\",\n"," \"verbose_score\": \"57.1/29.6/17.7/10.9 (BP = 0.980 ratio = 0.980 hyp_len = 60050 ref_len = 61287)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.3.1\"\n","}\n","\u001b[0m"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","CHECKPOINT_DIR=../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam\n","bash examples/backtranslation/sacrebleu.sh \\\n","    wmt08/europarl \\\n","    en-de \\\n","    data-bin/wmt18_en_de \\\n","    data-bin/wmt18_en_de/code \\\n","    $CHECKPOINT_DIR/checkpoint_best.pt"],"metadata":{"id":"GgEaqJMSQOsY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1672948921348,"user_tz":-60,"elapsed":44255,"user":{"displayName":"Dan G","userId":"10633818666769653523"}},"outputId":"d724f799-55eb-47a0-c421-7627227efd62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-05 20:01:20 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","2023-01-05 20:01:21 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 8000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 8000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 1024, 'input': 'source.txt'}, 'model': None, 'task': {'_name': 'translation', 'data': 'data-bin/wmt18_en_de', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2023-01-05 20:01:22 | INFO | fairseq.tasks.translation | [en] dictionary: 32232 types\n","2023-01-05 20:01:22 | INFO | fairseq.tasks.translation | [de] dictionary: 32232 types\n","2023-01-05 20:01:22 | INFO | fairseq_cli.interactive | loading model(s) from ../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_beam/checkpoint_best.pt\n","2023-01-05 20:01:26 | INFO | fairseq_cli.interactive | Sentence buffer size: 1024\n","2023-01-05 20:01:26 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2023-01-05 20:01:26 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2023-01-05 20:01:59 | INFO | fairseq_cli.interactive | Total time: 37.451 seconds; translation time: 24.826\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 26.0,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1\",\n"," \"verbose_score\": \"56.4/31.0/19.7/13.2 (BP = 1.000 ratio = 1.011 hyp_len = 57448 ref_len = 56829)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.3.1\"\n","}\n","\u001b[0m"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["Top"],"metadata":{"id":"I_-01vdmZrm0"}},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","CHECKPOINT_DIR=../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10\n","fairseq-train --fp16 \\\n","    data-bin/wmt18_en_de_para_plus_bt_top10 \\\n","    --upsample-primary 1 \\\n","    --source-lang en --target-lang de \\\n","    --arch transformer_wmt_en_de --share-all-embeddings \\\n","    --dropout 0.3 --weight-decay 0.0 \\\n","    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n","    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n","    --lr 0.0007 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n","    --max-tokens 3584 --update-freq 16 \\\n","    --max-update 11000 \\\n","    --save-dir $CHECKPOINT_DIR \\\n","    --wandb-project \"transformer_wmt_en_de_top10\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HI3Lf0exiSQM","outputId":"5e38d5a8-3a3d-4815-8b3f-62dddd55d9ee","executionInfo":{"status":"ok","timestamp":1673433388386,"user_tz":-60,"elapsed":9914523,"user":{"displayName":"Dan G","userId":"10633818666769653523"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-01-11 07:51:15 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","2023-01-11 07:51:17 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': 'transformer_wmt_en_de_top10', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3584, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3584, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 11000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [16], 'lr': [0.0007], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_wmt_en_de', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_wmt_en_de', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/wmt18_en_de_para_plus_bt_top10', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0007], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=3584, max_tokens_valid=3584, max_update=11000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang='en', stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang='de', task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[16], update_ordered_indices_seed=False, upsample_primary=1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project='transformer_wmt_en_de_top10', warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin/wmt18_en_de_para_plus_bt_top10', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': 1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0007]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0007]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2023-01-11 07:51:19 | INFO | fairseq.tasks.translation | [en] dictionary: 32232 types\n","2023-01-11 07:51:19 | INFO | fairseq.tasks.translation | [de] dictionary: 32232 types\n","2023-01-11 07:51:20 | INFO | fairseq_cli.train | TransformerModel(\n","  (encoder): TransformerEncoderBase(\n","    (dropout_module): FairseqDropout()\n","    (embed_tokens): Embedding(32232, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): TransformerEncoderLayerBase(\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (dropout_module): FairseqDropout()\n","        (activation_dropout_module): FairseqDropout()\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","  )\n","  (decoder): TransformerDecoderBase(\n","    (dropout_module): FairseqDropout()\n","    (embed_tokens): Embedding(32232, 512, padding_idx=1)\n","    (embed_positions): SinusoidalPositionalEmbedding()\n","    (layers): ModuleList(\n","      (0): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (1): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (2): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (3): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (4): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","      (5): TransformerDecoderLayerBase(\n","        (dropout_module): FairseqDropout()\n","        (self_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (activation_dropout_module): FairseqDropout()\n","        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (encoder_attn): MultiheadAttention(\n","          (dropout_module): FairseqDropout()\n","          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","        )\n","        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","      )\n","    )\n","    (output_projection): Linear(in_features=512, out_features=32232, bias=False)\n","  )\n",")\n","2023-01-11 07:51:20 | INFO | fairseq_cli.train | task: TranslationTask\n","2023-01-11 07:51:20 | INFO | fairseq_cli.train | model: TransformerModel\n","2023-01-11 07:51:20 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n","2023-01-11 07:51:20 | INFO | fairseq_cli.train | num. shared model params: 79,543,296 (num. trained: 79,543,296)\n","2023-01-11 07:51:20 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n","2023-01-11 07:51:21 | INFO | fairseq.data.data_utils | loaded 1,843 examples from: data-bin/wmt18_en_de_para_plus_bt_top10/valid.en-de.en\n","2023-01-11 07:51:22 | INFO | fairseq.data.data_utils | loaded 1,843 examples from: data-bin/wmt18_en_de_para_plus_bt_top10/valid.en-de.de\n","2023-01-11 07:51:22 | INFO | fairseq.tasks.translation | data-bin/wmt18_en_de_para_plus_bt_top10 valid en-de 1843 examples\n","2023-01-11 07:51:24 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight\n","2023-01-11 07:51:24 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight\n","2023-01-11 07:51:24 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n","2023-01-11 07:51:24 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.756 GB ; name = Tesla T4                                \n","2023-01-11 07:51:24 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n","2023-01-11 07:51:24 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n","2023-01-11 07:51:24 | INFO | fairseq_cli.train | max tokens per device = 3584 and max sentences per device = None\n","2023-01-11 07:51:24 | INFO | fairseq.trainer | Preparing to load checkpoint ../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10/checkpoint_last.pt\n","2023-01-11 07:51:42 | INFO | fairseq.trainer | Loaded checkpoint ../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10/checkpoint_last.pt (epoch 4 @ 6076 updates)\n","2023-01-11 07:51:42 | INFO | fairseq.trainer | loading train data for epoch 4\n","2023-01-11 07:51:45 | INFO | fairseq.data.data_utils | loaded 1,838,523 examples from: data-bin/wmt18_en_de_para_plus_bt_top10/train.en-de.en\n","2023-01-11 07:51:48 | INFO | fairseq.data.data_utils | loaded 1,838,523 examples from: data-bin/wmt18_en_de_para_plus_bt_top10/train.en-de.de\n","2023-01-11 07:51:48 | INFO | fairseq.tasks.translation | data-bin/wmt18_en_de_para_plus_bt_top10 train en-de 1838523 examples\n","2023-01-11 07:51:51 | INFO | fairseq.data.data_utils | loaded 1,804,086 examples from: data-bin/wmt18_en_de_para_plus_bt_top10/train1.en-de.en\n","2023-01-11 07:51:53 | INFO | fairseq.data.data_utils | loaded 1,804,086 examples from: data-bin/wmt18_en_de_para_plus_bt_top10/train1.en-de.de\n","2023-01-11 07:51:53 | INFO | fairseq.tasks.translation | data-bin/wmt18_en_de_para_plus_bt_top10 train1 en-de 1804086 examples\n","2023-01-11 07:51:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2028\n","epoch 004:   0% 0/2028 [00:00<?, ?it/s]\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdaniel-gorniak-stud\u001b[0m (\u001b[33mnlppw\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.13.8\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/fairseq/wandb/run-20230111_075155-e5416b36\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcheckpoints_en_de_parallel_bt_top10\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/nlppw/transformer_wmt_en_de_top10\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/nlppw/transformer_wmt_en_de_top10/runs/e5416b36\u001b[0m\n","2023-01-11 07:51:55 | INFO | fairseq.trainer | begin training epoch 4\n","2023-01-11 07:51:55 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 004:  51% 1026/2028 [33:54<33:59,  2.04s/it, loss=4.192, nll_loss=2.54, ppl=5.81, wps=26213.9, ups=0.5, wpb=52242.4, bsz=1812.7, num_updates=7100, lr=0.000525411, gnorm=0.371, loss_scale=16, train_wall=194, gb_free=11.3, wall=2061]2023-01-11 08:25:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0\n","epoch 004: 100% 2027/2028 [1:06:59<00:01,  1.95s/it, loss=4.135, nll_loss=2.479, ppl=5.58, wps=26336.8, ups=0.51, wpb=52073.7, bsz=1795.5, num_updates=8100, lr=0.00049191, gnorm=0.371, loss_scale=8, train_wall=193, gb_free=11.3, wall=4045]2023-01-11 08:58:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 004 | valid on 'valid' subset:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:   4% 1/24 [00:00<00:03,  6.66it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  12% 3/24 [00:00<00:01, 12.65it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  25% 6/24 [00:00<00:01, 17.71it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  38% 9/24 [00:00<00:00, 20.34it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  50% 12/24 [00:00<00:00, 21.63it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  62% 15/24 [00:00<00:00, 22.37it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  75% 18/24 [00:00<00:00, 22.82it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  88% 21/24 [00:01<00:00, 23.11it/s]\u001b[A\n","                                                                        \u001b[A2023-01-11 08:58:55 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 3.99 | nll_loss 2.237 | ppl 4.71 | wps 56283.3 | wpb 2345.4 | bsz 76.8 | num_updates 8103 | best_loss 3.99\n","2023-01-11 08:58:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 8103 updates\n","2023-01-11 08:58:55 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10/checkpoint4.pt\n","2023-01-11 08:59:01 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10/checkpoint4.pt\n","2023-01-11 08:59:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10/checkpoint4.pt (epoch 4 @ 8103 updates, score 3.99) (writing took 41.39831687399965 seconds)\n","2023-01-11 08:59:36 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n","2023-01-11 08:59:36 | INFO | train | epoch 004 | loss 4.19 | nll_loss 2.538 | ppl 5.81 | wps 26011.1 | ups 0.5 | wpb 52066.8 | bsz 1795.3 | num_updates 8103 | lr 0.000491819 | gnorm 0.375 | loss_scale 8 | train_wall 3920 | gb_free 11.3 | wall 4092\n","2023-01-11 08:59:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2028\n","epoch 005:   0% 0/2028 [00:00<?, ?it/s]2023-01-11 08:59:37 | INFO | fairseq.trainer | begin training epoch 5\n","2023-01-11 08:59:37 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 005:  53% 1079/2028 [35:44<32:31,  2.06s/it, loss=4.076, nll_loss=2.416, ppl=5.34, wps=26211.3, ups=0.5, wpb=52160.2, bsz=1740.7, num_updates=9100, lr=0.000464095, gnorm=0.35, loss_scale=16, train_wall=194, gb_free=11.3, wall=6074]2023-01-11 09:35:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0\n","epoch 005: 100% 2027/2028 [1:07:10<00:01,  1.98s/it, loss=4.044, nll_loss=2.383, ppl=5.22, wps=26071.4, ups=0.5, wpb=51904.2, bsz=1797.6, num_updates=10100, lr=0.000440522, gnorm=0.348, loss_scale=16, train_wall=194, gb_free=11.3, wall=8066]2023-01-11 10:06:48 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 005 | valid on 'valid' subset:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:   8% 2/24 [00:00<00:01, 15.47it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  17% 4/24 [00:00<00:01, 17.06it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  29% 7/24 [00:00<00:00, 20.35it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  42% 10/24 [00:00<00:00, 21.17it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  54% 13/24 [00:00<00:00, 22.76it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  67% 16/24 [00:00<00:00, 23.05it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  79% 19/24 [00:00<00:00, 22.84it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  92% 22/24 [00:01<00:00, 22.85it/s]\u001b[A\n","                                                                        \u001b[A2023-01-11 10:06:49 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 3.922 | nll_loss 2.159 | ppl 4.47 | wps 55107.3 | wpb 2345.4 | bsz 76.8 | num_updates 10130 | best_loss 3.922\n","2023-01-11 10:06:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 10130 updates\n","2023-01-11 10:06:49 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10/checkpoint5.pt\n","2023-01-11 10:06:54 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10/checkpoint5.pt\n","2023-01-11 10:07:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10/checkpoint5.pt (epoch 5 @ 10130 updates, score 3.922) (writing took 18.10800252899935 seconds)\n","2023-01-11 10:07:07 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n","2023-01-11 10:07:07 | INFO | train | epoch 005 | loss 4.071 | nll_loss 2.41 | ppl 5.32 | wps 26053.4 | ups 0.5 | wpb 52066.6 | bsz 1796.2 | num_updates 10130 | lr 0.000439869 | gnorm 0.354 | loss_scale 16 | train_wall 3932 | gb_free 11.4 | wall 8143\n","2023-01-11 10:07:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2028\n","epoch 006:   0% 0/2028 [00:00<?, ?it/s]2023-01-11 10:07:08 | INFO | fairseq.trainer | begin training epoch 6\n","2023-01-11 10:07:08 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 006:   4% 91/2028 [03:03<1:03:36,  1.97s/it, loss=4.012, nll_loss=2.346, ppl=5.08, wps=23594.9, ups=0.45, wpb=51989.1, bsz=1768.5, num_updates=10200, lr=0.000438357, gnorm=0.339, loss_scale=16, train_wall=194, gb_free=11.3, wall=8286]2023-01-11 10:10:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0\n","epoch 006:  43% 870/2028 [28:54<38:55,  2.02s/it, loss=4.008, nll_loss=2.342, ppl=5.07, wps=26138.7, ups=0.5, wpb=52020.7, bsz=1759.3, num_updates=10900, lr=0.000424048, gnorm=0.341, loss_scale=16, train_wall=194, gb_free=11.3, wall=9680]2023-01-11 10:36:04 | INFO | fairseq_cli.train | Stopping training due to num_updates: 11000 >= max_update: 11000\n","2023-01-11 10:36:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 006 | valid on 'valid' subset:   0% 0/24 [00:00<?, ?it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:   8% 2/24 [00:00<00:01, 15.46it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  17% 4/24 [00:00<00:01, 17.53it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  29% 7/24 [00:00<00:00, 20.71it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  42% 10/24 [00:00<00:00, 21.64it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  54% 13/24 [00:00<00:00, 23.29it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  67% 16/24 [00:00<00:00, 23.24it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  79% 19/24 [00:00<00:00, 23.34it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  92% 22/24 [00:00<00:00, 23.53it/s]\u001b[A\n","                                                                        \u001b[A2023-01-11 10:36:05 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 3.9 | nll_loss 2.136 | ppl 4.39 | wps 56170.1 | wpb 2345.4 | bsz 76.8 | num_updates 11000 | best_loss 3.9\n","2023-01-11 10:36:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 11000 updates\n","2023-01-11 10:36:05 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10/checkpoint_best.pt\n","2023-01-11 10:36:10 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10/checkpoint_best.pt\n","2023-01-11 10:36:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint ../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10/checkpoint_best.pt (epoch 6 @ 11000 updates, score 3.9) (writing took 10.464399738999418 seconds)\n","2023-01-11 10:36:16 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)\n","2023-01-11 10:36:16 | INFO | train | epoch 006 | loss 4.005 | nll_loss 2.338 | ppl 5.06 | wps 25941.4 | ups 0.5 | wpb 52127 | bsz 1786.1 | num_updates 11000 | lr 0.000422116 | gnorm 0.343 | loss_scale 16 | train_wall 1692 | gb_free 11.2 | wall 9891\n","2023-01-11 10:36:16 | INFO | fairseq_cli.train | done training in 9861.3 seconds\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","CHECKPOINT_DIR=../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10\n","bash examples/backtranslation/sacrebleu.sh \\\n","    wmt17 \\\n","    en-de \\\n","    data-bin/wmt18_en_de \\\n","    data-bin/wmt18_en_de/code \\\n","    $CHECKPOINT_DIR/checkpoint_best.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"enFZjg1jfwxr","executionInfo":{"status":"ok","timestamp":1673435050934,"user_tz":-60,"elapsed":58569,"user":{"displayName":"Dan G","userId":"10633818666769653523"}},"outputId":"48959b8c-91bb-4874-e3f1-b81e4b0453ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sacreBLEU: Downloading http://data.statmt.org/wmt17/translation-task/test.tgz to /root/.sacrebleu/wmt17/raw/wmt17.test.tgz\n","sacreBLEU: Extracting /root/.sacrebleu/wmt17/raw/wmt17.test.tgz to /root/.sacrebleu/wmt17/raw\n","2023-01-11 11:03:19 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","2023-01-11 11:03:21 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 8000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 8000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 1024, 'input': 'source.txt'}, 'model': None, 'task': {'_name': 'translation', 'data': 'data-bin/wmt18_en_de', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2023-01-11 11:03:21 | INFO | fairseq.tasks.translation | [en] dictionary: 32232 types\n","2023-01-11 11:03:21 | INFO | fairseq.tasks.translation | [de] dictionary: 32232 types\n","2023-01-11 11:03:21 | INFO | fairseq_cli.interactive | loading model(s) from ../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10/checkpoint_best.pt\n","2023-01-11 11:03:28 | INFO | fairseq_cli.interactive | Sentence buffer size: 1024\n","2023-01-11 11:03:28 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2023-01-11 11:03:28 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2023-01-11 11:04:09 | INFO | fairseq_cli.interactive | Total time: 47.947 seconds; translation time: 31.154\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 23.5,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1\",\n"," \"verbose_score\": \"57.3/29.8/17.9/11.2 (BP = 0.973 ratio = 0.973 hyp_len = 59654 ref_len = 61287)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.3.1\"\n","}\n","\u001b[0m"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["%%shell\n","#!/bin/bash\n","cd ./fairseq/\n","CHECKPOINT_DIR=../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10\n","bash examples/backtranslation/sacrebleu.sh \\\n","    wmt08/europarl \\\n","    en-de \\\n","    data-bin/wmt18_en_de \\\n","    data-bin/wmt18_en_de/code \\\n","    $CHECKPOINT_DIR/checkpoint_best.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VMQYMqPBfyUR","executionInfo":{"status":"ok","timestamp":1673435240310,"user_tz":-60,"elapsed":44081,"user":{"displayName":"Dan G","userId":"10633818666769653523"}},"outputId":"25b0c60c-2705-46fb-f682-25c35b13c596"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sacreBLEU: Downloading http://statmt.org/wmt08/test.tgz to /root/.sacrebleu/wmt08/europarl/raw/wmt08_europarl.test.tgz\n","sacreBLEU: Extracting /root/.sacrebleu/wmt08/europarl/raw/wmt08_europarl.test.tgz to /root/.sacrebleu/wmt08/europarl/raw\n","2023-01-11 11:06:40 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","2023-01-11 11:06:42 | INFO | fairseq_cli.interactive | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 8000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 8000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 1024, 'input': 'source.txt'}, 'model': None, 'task': {'_name': 'translation', 'data': 'data-bin/wmt18_en_de', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2023-01-11 11:06:42 | INFO | fairseq.tasks.translation | [en] dictionary: 32232 types\n","2023-01-11 11:06:42 | INFO | fairseq.tasks.translation | [de] dictionary: 32232 types\n","2023-01-11 11:06:42 | INFO | fairseq_cli.interactive | loading model(s) from ../drive/MyDrive/NLP/checkpoints_en_de_parallel_bt_top10/checkpoint_best.pt\n","2023-01-11 11:06:47 | INFO | fairseq_cli.interactive | Sentence buffer size: 1024\n","2023-01-11 11:06:47 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n","2023-01-11 11:06:47 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n","2023-01-11 11:07:18 | INFO | fairseq_cli.interactive | Total time: 36.537 seconds; translation time: 24.044\n","{\n"," \"name\": \"BLEU\",\n"," \"score\": 26.3,\n"," \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1\",\n"," \"verbose_score\": \"56.9/31.4/20.1/13.6 (BP = 0.994 ratio = 0.994 hyp_len = 56461 ref_len = 56829)\",\n"," \"nrefs\": \"1\",\n"," \"case\": \"mixed\",\n"," \"eff\": \"no\",\n"," \"tok\": \"13a\",\n"," \"smooth\": \"exp\",\n"," \"version\": \"2.3.1\"\n","}\n","\u001b[0m"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":8}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}